name: clip-batch-inference

resources:
  accelerators: T4:1  # Use 1 T4 GPU

num_nodes: 2 

# file_mounts:
#   /artifacts:
#     name: kych-clip-embeddings
#     store: S3
#     mode: MOUNT
envs:
  HF_TOKEN: ${HF_TOKEN}  

# working directory, you may need to change this to your own path
workdir: ~/skypilot/examples/batch_inference

setup: |
  # Install required packages
  pip install torch==2.1.0 torchvision==0.16.0 ftfy regex tqdm
  pip install datasets webdataset requests Pillow open_clip_torch
  pip install fastapi uvicorn aiohttp pandas pyarrow tenacity

run: |
  # Start the inference server in the background
  python inference_server.py &
  SERVER_PID=$!

  # Wait for server to start
  echo "Waiting for server to start..."
  sleep 10

  # Run the dataloader with specific parameters
  python ~/sky_workdir/dataloader.py \
    --start-idx 0 \
    --end-idx 1000000 \
    --server-url "http://localhost:5005" \
    --output "/tmp/embeddings.parquet" 

  # Cleanup: Kill the server process
  kill $SERVER_PID

  # Wait for server to shutdown gracefully
  wait $SERVER_PID

  echo "Processing complete. Results saved in node-specific files under /tmp/"
